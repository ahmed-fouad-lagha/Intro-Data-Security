{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ahmed-fouad-lagha/Intro-Data-Security/blob/main/module_01_foundations/Lab_1a_DNN_Training_and_Robust_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0de37f",
   "metadata": {},
   "source": [
    "# **Lab 1: Deep Neural Network Training & Robust Models**\n",
    "\n",
    "**Course:** Introduction to Data Security Pr. (Master's Level)  \n",
    "**Module 1:** Foundations  \n",
    "**Estimated Time:** 120 minutes\n",
    "\n",
    "---\n",
    "In this notebook, we will use the basic training functionalities of SecML-Torch to train a regular PyTorch Deep Neural Network (DNN) classifier.\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Train** deep neural networks on standard image classification dataset (MNIST)\n",
    "2. **Evaluate** model performance using standard metrics (accuracy, loss, confusion matrix)\n",
    "3. **Understand** the difference between standard models and robust models\n",
    "4. **Load** and compare pre-trained robust models\n",
    "5. **Analyze** vulnerability of standard models to adversarial perturbations\n",
    "6. **Establish** baseline models for subsequent security labs\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Part 1: Dataset Loading & Preprocessing](#part1)\n",
    "3. [Part 2: Training a Standard DNN](#part2)\n",
    "4. [Part 3: Evaluating Model Performance](#part3)\n",
    "5. [Part 4: Saving & Loading Models](#part4)\n",
    "6. [Part 5: Loading Pre-trained & Robust Models](#part5)\n",
    "7. [Exercises](#exercises)\n",
    "8. [Conclusion & Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd653195",
   "metadata": {},
   "source": [
    "## **Setup & Imports** <a name=\"setup\"></a>\n",
    "\n",
    "First, we'll install necessary libraries and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c841f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision matplotlib numpy scikit-learn tqdm secml-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1029eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68fd0b",
   "metadata": {},
   "source": [
    "## **Part 1: Dataset Loading & Preprocessing** <a name=\"part1\"></a>\n",
    "\n",
    "We'll work with **MNIST** (handwritten digits) as our primary dataset. MNIST is a standard benchmark for:\n",
    "- Image classification\n",
    "- Neural network training\n",
    "- Adversarial robustness research\n",
    "\n",
    "**Dataset Details:**\n",
    "- **Training samples:** 60,000\n",
    "- **Test samples:** 10,000\n",
    "- **Image size:** 28Ã—28 grayscale\n",
    "- **Classes:** 10 (digits 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff32d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor and scale to [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches (train): {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfc1e9",
   "metadata": {},
   "source": [
    "### **Visualize Sample Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training samples\n",
    "def show_images(dataset, num_samples=10):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[i]\n",
    "        # Denormalize for visualization\n",
    "        image = image * 0.3081 + 0.1307\n",
    "        axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bec0cb",
   "metadata": {},
   "source": [
    "## **Part 2: Training a Standard DNN** <a name=\"part2\"></a>\n",
    "\n",
    "We'll implement a simple **fully connected network (MLP)** for MNIST classification.\n",
    "\n",
    "**Architecture:**\n",
    "- Flatten 28x28 to 784\n",
    "- FC Layer 1: 784 -> 200\n",
    "- FC Layer 2: 200 -> 200\n",
    "- FC Layer 3: 200 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9062822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(torch.nn.Module):\n",
    "    \"\"\"Simple fully connected network for MNIST classification.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 200)\n",
    "        self.fc3 = torch.nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Initialize model\n",
    "net = MNISTNet().to(device)\n",
    "print(net)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65c59c",
   "metadata": {},
   "source": [
    "### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from secmlt.models.pytorch.base_pytorch_trainer import BasePyTorchTrainer\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Train with SecML-Torch trainer\n",
    "trainer = BasePyTorchTrainer(optimizer=optimizer, epochs=5)\n",
    "model = BasePytorchClassifier(model=net, trainer=trainer)\n",
    "\n",
    "model.train(dataloader=train_loader)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d886",
   "metadata": {},
   "source": [
    "## **Part 3: Evaluating Model Performance** <a name=\"part3\"></a>\n",
    "\n",
    "Now we'll evaluate our trained model on the test set using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secmlt.metrics.classification import Accuracy\n",
    "\n",
    "accuracy = Accuracy()(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8ee9f",
   "metadata": {},
   "source": [
    "## **Part 4: Saving & Loading Models** <a name=\"part4\"></a>\n",
    "\n",
    "We'll save our **standard** model and demonstrate how to load a saved model checkpoint.\n",
    "In later labs, you'll load **robust** checkpoints for side-by-side comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our trained standard model\n",
    "model_save_path = 'standard_mnist_dnn.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'accuracy': accuracy\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def load_model(model_path, model_class, device):\n",
    "    \"\"\"Load a saved model.\"\"\"\n",
    "    model = model_class().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model, checkpoint\n",
    "\n",
    "# Load our saved model\n",
    "loaded_model, checkpoint = load_model(model_save_path, MNISTNet, device)\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Saved model accuracy: {checkpoint['accuracy'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9316c56",
   "metadata": {},
   "source": [
    "## **Part 5: Loading Pre-trained & Robust Models** <a name=\"part5\"></a>\n",
    "\n",
    "In this section, we load a standard pre-trained model from torchvision and a robust model from RobustBench.\n",
    "This shows how SecML-Torch wraps any PyTorch model with a unified interface.\n",
    "\n",
    "**Note:** The downloads below can take a few minutes the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc874cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "try:\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import robustbench\n",
    "except ImportError:\n",
    "    %pip install requests pillow git+https://github.com/RobustBench/robustbench.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0db85",
   "metadata": {},
   "source": [
    "### **5.1 Loading and Preprocessing an Image**\n",
    "\n",
    "We'll download a sample image and prepare it for inference using the standard ImageNet preprocessing pipeline: resize to 256, center-crop to 224, and convert to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import get_model\n",
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from robustbench.utils import load_model\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "img_url = (\n",
    "    \"https://github.com/ajschumacher/imagen/blob/master/imagen/\"\n",
    "    \"n02342885_10908_hamster.jpg?raw=true\"\n",
    ")\n",
    "labels_url = (\n",
    "    \"https://raw.githubusercontent.com/\"\n",
    "    \"anishathalye/imagenet-simple-labels/master/\"\n",
    "    \"imagenet-simple-labels.json\"\n",
    ")\n",
    "\n",
    "resp = requests.get(img_url, timeout=30)\n",
    "labels_resp = requests.get(labels_url, timeout=30)\n",
    "imagenet_labels = json.loads(labels_resp.text)\n",
    "img = Image.open(io.BytesIO(resp.content)).convert(\"RGB\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "imagenet_input_tensor = imagenet_transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89300a08",
   "metadata": {},
   "source": [
    "### **5.2 Importing a Pre-trained Model from Torchvision**\n",
    "\n",
    "We load a pre-trained Vision Transformer (ViT) model from torchvision and wrap it using `BasePytorchClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_net = get_model(\"vit_b_16\", weights=\"IMAGENET1K_V1\")\n",
    "imagenet_net.to(device)\n",
    "imagenet_net.eval()\n",
    "\n",
    "imagenet_model = BasePytorchClassifier(imagenet_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71658af3",
   "metadata": {},
   "source": [
    "### **5.3 Making Predictions with the Pre-trained Model**\n",
    "\n",
    "We'll classify the image and map the predicted class index to a human-readable label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_pred = imagenet_model.predict(imagenet_input_tensor.unsqueeze(0).to(device))\n",
    "imagenet_label = imagenet_labels[imagenet_pred.item()]\n",
    "print(f\"Predicted class index: {imagenet_pred.item()}\")\n",
    "print(f\"Predicted class label: {imagenet_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630a484",
   "metadata": {},
   "source": [
    "### **5.4 Loading a Robust Model from RobustBench**\n",
    "\n",
    "RobustBench provides models trained for adversarial robustness. We'll load a model robust to $L_\\infty$ perturbations and wrap it the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = load_model(model_name=\"Salman2020Do_R18\", dataset=\"imagenet\", threat_model=\"Linf\")\n",
    "robust_net.to(device)\n",
    "robust_net.eval()\n",
    "\n",
    "robust_model = BasePytorchClassifier(robust_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c77ec",
   "metadata": {},
   "source": [
    "### **5.5 Comparing Predictions**\n",
    "\n",
    "Robust models may trade clean accuracy for resilience, but on this example both models should agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_pred = robust_model.predict(imagenet_input_tensor.unsqueeze(0).to(device))\n",
    "robust_label = imagenet_labels[robust_pred.item()]\n",
    "print(f\"Predicted class index: {robust_pred.item()}\")\n",
    "print(f\"Predicted class label: {robust_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fcbc7",
   "metadata": {},
   "source": [
    "## **Conclusion & Next Steps** <a name=\"conclusion\"></a>\n",
    "---\n",
    "\n",
    "### **What You Learned**\n",
    "\n",
    "- **Neural Network Training:** Built and trained a DNN from scratch  \n",
    "- **Model Evaluation:** Used accuracy, confusion matrix, and classification reports  \n",
    "- **Robust Models:** Understood the concept of adversarial robustness  \n",
    "- **Model Persistence:** Saved and loaded trained models  \n",
    "- **Baseline Establishment:** Created standard models for future attack labs  \n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1. **Standard models** achieve high clean accuracy but are vulnerable to adversarial attacks\n",
    "2. **Robust models** trade some clean accuracy for adversarial resilience\n",
    "3. **Adversarial training** is the most effective defense but computationally expensive\n",
    "4. **Model architecture** affects both performance and robustness\n",
    "\n",
    "### **Preparing for Upcoming Labs**\n",
    "\n",
    "Module 2: Implement and defend against evasion attacks\n",
    "Module 3-4: Execute and detect poisoning attacks\n",
    "Module 5: Create and mitigate sponge attacks\n",
    "Module 6: Launch and prevent privacy attacks\n",
    "Module 7: Generate and evaluate synthetic data\n",
    "Module 8: Deploy comprehensive defense systems\n",
    "\n",
    "### **Additional Resources**\n",
    "\n",
    "**Foundational Papers:**\n",
    "- [Explaining and Harnessing Adversarial Examples (Goodfellow et al., 2015)](https://arxiv.org/abs/1412.6572)\n",
    "- [Towards Deep Learning Models Resistant to Adversarial Attacks (Madry et al., 2018)](https://arxiv.org/abs/1706.06083)\n",
    "- [Adversarial Examples Are Not Bugs, They Are Features (Ilyas et al., 2019)](https://arxiv.org/abs/1905.02175)\n",
    "- [SoK: Security and Privacy in Machine Learning (Papernot et al., 2018)](https://ieeexplore.ieee.org/document/8406613)\n",
    "- [The NIST Adversarial ML Framework](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)\n",
    "\n",
    "**Industry Standards:**\n",
    "- MITRE ATLAS: Adversarial Threat Landscape for AI Systems\n",
    "- OWASP Machine Learning Security Top 10\n",
    "- ISO/IEC 24029: AI Trustworthiness\n",
    "\n",
    "**Tools & Frameworks:**\n",
    "- [SecML-Torch](https://secml-torch.readthedocs.io/)\n",
    "- [Microsoft Threat Modeling Tool](https://www.microsoft.com/en-us/securityengineering/sdl/threatmodeling)\n",
    "- [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
